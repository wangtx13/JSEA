2002 m a l l e t m achine languag e ~mccallum 1 0 further ` l i e n s e classify io serializable arrays types alphabet types feature selection types feature vector types instance types instance list types labeling an training a balanced winnow on line classifier given a labeled instance x y algorithm computes dot x wi w1 wc where wi weight vector i instance classified j value dot x wj largest among dot products <p> weight vectors are updated whenever classifier makes a mistake or just barely got correct answer highest dot product within delta percent higher than second highest suppose classifier guessed j and answer was j each feature i that present multiply w ji 1 epsilon and multiply w j i 1+epsilon <p> above procedure done multiple times to training examples 5 and epsilon cut cooling rate at each iteration cutting epsilon half author gary huang <a href= mailto ghuang >ghuang edu< a> balanced winnow trainer classifier trainer< balanced winnow> boostable serializable serial u = 1 l 0 5 d e f a u l t e p s i l o n = 5 0 1 d e f a u l t d e l t a = 1 30 d e f a u l t m a x i t e r a t i o n s = 30 0 5 d e f a u l t o o l i n g r a t e = 5 m epsilon m delta m max iterations m cooling rate weights one each and feature initialized to 1 each there an additional feature weight that set to 1 in every example it remains constant used to prevent instance from having 0 dot product a m weights balanced winnow classifier balanced winnow get classifier classifier constructor sets all features to defaults balanced winnow trainer d e f a u l t e p s i l o n d e f a u l t d e l t a d e f a u l t m a x i t e r a t i o n s d e f a u l t o o l i n g r a t e epsilon percentage which to increase decrease weight vectors when an example misclassified delta percentage which highest and correct dot product should exceed second highest dot product before we consider an example to be correctly classified margin width when adjusting weights max iterations maximum number times to loop through training examples cooling rate percentage epsilon to decrease after each iteration balanced winnow trainer epsilon delta max iterations cooling rate m epsilon = epsilon m delta = delta m max iterations = max iterations m cooling rate = cooling rate trains classifier on instance list updating weight vectors appropriate training list instance list to be trained on classifier containing learned weights balanced winnow train instance list training list feature selection selected features = training list get feature selection selected features != xxx attend to feature selection!!! unsupported operation feature selection not yet epsilon = m epsilon alphabet dict = alphabet training list get data alphabet num labels = training list get target alphabet size num feats = dict size m weights = num labels num feats+1 init weights to 1 i = 0 i < num labels i++ arrays fill m weights i 1 0 loop through training instances multiple times results = num labels iter = 0 iter < m max iterations iter++ loop through all instances ii = 0 ii < training list size ii++ instance inst = training list get ii labeling labeling = inst get labeling feature vector fv = feature vector inst get data fvisize = fv num locations correct index = labeling get best index arrays fill results 0 compute dot x wi each i lpos = 0 lpos < num labels lpos++ fvi = 0 fvi < fvisize fvi++ fi = fv index at location fvi vi = fv value at location fvi results lpos += vi m weights lpos fi extra value comes from extra feature present in all examples results lpos += m weights lpos num feats get indices classes 2 highest dot products predicted index = 0 second highest index = 0 max = m i n v a l u e second max = m i n v a l u e i = 0 i < num labels i++ results i > max second max = max max = results i second highest index = predicted index predicted index = i results i > second max second max = results i second highest index = i adjust weights example mispredicted or just barely correct predicted index != correct index fvi = 0 fvi < fvisize fvi++ fi = fv index at location fvi m weights predicted index fi = 1 epsilon m weights correct index fi = 1 + epsilon m weights predicted index num feats = 1 epsilon m weights correct index num feats = 1 + epsilon max second max 1 < m delta fvi = 0 fvi < fvisize fvi++ fi = fv index at location fvi m weights second highest index fi = 1 epsilon m weights correct index fi = 1 + epsilon m weights second highest index num feats = 1 epsilon m weights correct index num feats = 1 + epsilon cut epsilon cooling rate epsilon = 1 m cooling rate classifier = balanced winnow training list get pipe m weights classifier 