2002 m a l l e t m achine languag e ~mccallum 1 0 further ` l i e n s e classify random arrays logging types logger maths ada boost can handle multi problems binary classification can also use <tt> ada boost trainer< tt> <p> yoav freund and robert e schapire experiments a boosting algorithm in journal proceedings 13th international conference 1996 princeton ~schapire papers freund sc96b ps z author gary huang <a href= mailto ghuang >ghuang edu< a> ada boost m2 trainer classifier trainer< ada boost m2> logger logger = logger get logger ada boost m2 trainer get name m a x n u m r e s a m p l i n g i t e r a t i o n s = 10 classifier trainer weak learner num rounds ada boost m2 classifier ada boost m2 get classifier classifier ada boost m2 trainer classifier trainer weak learner num rounds ! weak learner boostable illegal argument weak learner not boostable num rounds <= 0 illegal argument number rounds must be positive weak learner = weak learner num rounds = num rounds ada boost m2 trainer classifier trainer weak learner weak learner 100 boosting that resamples instances using their weights ada boost m2 train instance list training list feature selection selected features = training list get feature selection selected features != unsupported operation feature selection not yet num classes = training list get target alphabet size num instances = training list size construct set b a list instances size num instances num classes 1 each instance in list will have weights mislabel associated classes intance doesn t belong to instance list training insts = instance list training list get pipe set initial weights to be uniform weights = num instances num classes 1 w = 1 0 weights length arrays fill weights w indices = weights length num added = 0 i = 0 i < num instances i++ instance inst = training list get i index = inst get labeling get best index j = 0 j < num classes j++ j != index training insts add inst 1 indices num added = j num added++ random random = random classifier weak learners = classifier num rounds classifier weights = num rounds exponents = weights length inst indices = weights length i = 0 i < inst indices length i++ inst indices i = i boosting iterations round = 0 round < num rounds round++ logger info =========== ada boost m2 trainer round + round+1 + begin sample instances from set b using weight vector to train weak learner epsilon instance list round training insts = instance list training insts get pipe resampling iterations = 0 epsilon = 0 sample indices = sample weights inst indices weights random round training insts = instance list training insts get pipe sample indices length i = 0 i < sample indices length i++ instance inst = training insts get sample indices i round training insts add inst 1 weak learners round = weak learner train round training insts calculate pseudo loss weak learner i = 0 i < training insts size i++ instance inst = training insts get i classification = weak learners round classify inst ht correct = value correct label ht wrong = get labeling value indices i epsilon += weights i 1 ht correct + ht wrong exponents i = 1 + ht correct ht wrong epsilon = 0 5 resampling iterations++ maths almost equals epsilon 0 resampling iterations < m a x n u m r e s a m p l i n g i t e r a t i o n s stop boosting when pseudo loss 0 ignoring weak classifier trained round maths almost equals epsilon 0 logger info ada boost m2 trainer stopped at + round+1 + + num rounds + pseudo loss= + epsilon we are in first round have to use weak classifier in any num classifiers to use = round == 0 ? 1 round round == 0 classifier weights 0 = 1 classifier weights2 = num classifiers to use classifier weak learners2 = classifier num classifiers to use arraycopy classifier weights 0 classifier weights2 0 num classifiers to use arraycopy weak learners 0 weak learners2 0 num classifiers to use i = 0 i < classifier weights2 length i++ logger info ada boost m2 trainer weight weak learner + i + = + classifier weights2 i ada boost m2 training insts get pipe weak learners2 classifier weights2 beta = epsilon 1 epsilon classifier weights round = math log 1 0 beta update and normalize weights sum = 0 i = 0 i < weights length i++ weights i = math pow beta 0 5 exponents i sum += weights i matrix ops times equals weights 1 0 sum logger info =========== ada boost m2 trainer round + round+1 + finished pseudo loss = + epsilon i = 0 i < classifier weights length i++ logger info ada boost m2 trainer weight weak learner + i + = + classifier weights i classifier = ada boost m2 training insts get pipe weak learners classifier weights classifier an ints same size data where samples are randomly chosen from data using weights vector sample weights data weights random random weights length != data length illegal argument length weight vector must equal number data points sum weights = 0 i = 0 i < data length i++ weights i < 0 illegal argument weight vector must be non negative sum weights += weights i sum weights <= 0 illegal argument weights must sum to positive value sample = data length probabilities = data length sum probs = 0 i = 0 i < data length i++ sum probs += random next probabilities i = sum probs matrix ops times equals probabilities sum weights sum probs make sure rounding didn t mess things up probabilities data length 1 = sum weights sampling a = 0 b = 0 sum probs = 0 a < data length b < data length sum probs += weights b a < data length probabilities a <= sum probs sample a = data b a++ b++ sample 