2011 m a l l e t m achine languag e ~mccallum 1 0 further ` l i e n s e classify io serializable list hash map logging logger classify constraints ge max ent g e constraint classify constraints ge max ent k l f l g e constraints classify constraints ge max ent l2 f l g e constraints classify constraints ge max ent range l2 f l g e constraints optimize limited memory b f g s optimize optimizable optimize optimizer types instance list logger progress message logger training max ent models labeled features using generalized expectation criteria based on from labeled features using generalized expectation criteria gregory druck gideon mann andrew mc callum s i g i r 2008 author gregory druck <a href= mailto gdruck >gdruck edu< a> better explanations given in max ent optimizable g e max ent g e range trainer classifier trainer< max ent> classifier trainer optimization< max ent> boostable serializable serial u = 1 l logger logger = logger get logger max ent g e range trainer get name logger progress logger = progress message logger get logger max ent g e range trainer get name + pl these are using from command line normalize = use values = constraints num iterations = 0 max iterations = m a x v a l u e temperature = 1 gaussian prior variance = 1 list< max ent g e constraint> constraints instance list training list = max ent classifier = max ent optimizable g e ge = optimizer opt = max ent g e range trainer max ent g e range trainer list< max ent g e constraint> constraints constraints = constraints max ent g e range trainer list< max ent g e constraint> constraints max ent classifier constraints = constraints classifier = classifier set constraints filename constraints = filename set temperature temp temperature = temp set gaussian prior variance variance gaussian prior variance = variance max ent get classifier classifier set use values flag use values = flag set normalize normalize normalize = normalize optimizable gradient value get optimizable instance list training list ge == ge = max ent optimizable g e training list constraints classifier ge set temperature temperature ge set gaussian prior variance gaussian prior variance ge optimizer get optimizer get optimizable training list opt == opt = limited memory b f g s ge opt set optimizer optimizer opt opt = opt specifies maximum number iterations to run during a single call to <code>train< code> or <code>train feature induction< code> trainer set max iterations iter max iterations = iter get iteration num iterations max ent train instance list training list train training list max iterations max ent train instance list train max iterations training list = train constraints == constraints != hash map< > constraints map = feature constraint read range constraints from constraints training list logger info number constraints + constraints map size constraints = list< max ent g e constraint> max ent range l2 f l g e constraints ge constraints = max ent range l2 f l g e constraints train get data alphabet size train get target alphabet size use values normalize fi constraints map key set dist = constraints map get fi = 0 < dist length li++ ! infinite dist 0 ge constraints add constraint fi dist 0 dist 1 1 constraints add ge constraints get optimizable training list get optimizer opt limited memory b f g s limited memory b f g s opt reset logger fine training list size = +training list size opt optimize max iterations num iterations += max iterations e e print stack trace logger info catching saying converged max iterations == m a x v a l u e opt limited memory b f g s run it again because in our and sam roweis experience b f g s can still eke out more likelihood after first convergence re running without being restricted its gradient history limited memory b f g s opt reset opt optimize max iterations num iterations += max iterations e e print stack trace logger info catching saying converged progress logger info progress messages are on one line move on classifier = ge get classifier classifier 