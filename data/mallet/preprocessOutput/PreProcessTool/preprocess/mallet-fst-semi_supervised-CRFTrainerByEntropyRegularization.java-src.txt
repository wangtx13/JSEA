2009 m a l l e t m achine languag e ~mccallum 1 0 further ` l i e n s e semi supervised logging logger r f r f optimizable gradient values r f optimizable label likelihood transducer transducer trainer optimize limited memory b f g s optimize optimizable optimize optimizer types instance list logger a r f trainer that maximizes log likelihood plus a weighted entropy regularization term on unlabeled data intuitively it aims to make r f s predictions on unlabeled data more confident references feng jiao shaojun wang chi hoon lee russell greiner dale schuurmans semi supervised conditional random fields improved sequence segmentation and labeling a l 2006 gideon mann andrew mc callum efficient computation entropy gradient semi supervised conditional random fields h l t n a a l 2007 author gregory druck r f trainer entropy regularization transducer trainer transducer trainer optimization logger logger = logger get logger r f trainer entropy regularization get name d e f a u l t n u m r e s e t s = 1 d e f a u l t e r s a l i n g f a t o r = 1 d e f a u l t g a u s s i a n p r i o r v a r i a n e = 1 converged iteration ent reg scaling factor gaussian prior variance r f crf limited memory b f g s bfgs r f trainer entropy regularization r f crf crf = crf iteration = 0 ent reg scaling factor = d e f a u l t e r s a l i n g f a t o r gaussian prior variance = d e f a u l t g a u s s i a n p r i o r v a r i a n e set gaussian prior variance variance gaussian prior variance = variance sets scaling factor entropy regularization term in jiao et al 06 gamma gamma set entropy weight gamma ent reg scaling factor = gamma override get iteration iteration override transducer get transducer crf override finished training converged not used because we require both labeled and unlabeled data train instance list training set num iterations runtime use train instance list labeled instance list unlabeled num iterations instead performs r f training label likelihood and entropy regularization r f first trained label likelihood only parameter setting used a starting point combined optimization labeled labeled data only used label likelihood term unlabeled unlabeled data only used entropy regularization term num iterations number iterations training has converged train instance list labeled instance list unlabeled num iterations iteration == 0 train log likelihood only first r f optimizable label likelihood likelihood = r f optimizable label likelihood crf labeled likelihood set gaussian prior variance gaussian prior variance bfgs = limited memory b f g s likelihood logger info r f about to train +num iterations+ iterations i = 0 i < num iterations i++ converged = bfgs optimize 1 iteration++ logger info r f finished one iteration maximizer i= +i run evaluators illegal argument e e print stack trace logger info catching saying converged converged = e e print stack trace logger info catching saying converged converged = converged logger info r f training has converged i= +i iteration = 0 train log likelihood + entropy regularization r f optimizable label likelihood likelihood = r f optimizable label likelihood crf labeled likelihood set gaussian prior variance gaussian prior variance r f optimizable entropy regularization regularization = r f optimizable entropy regularization crf unlabeled regularization set scaling factor ent reg scaling factor r f optimizable gradient values reg likelihood = r f optimizable gradient values crf optimizable gradient value likelihood regularization bfgs = limited memory b f g s reg likelihood converged = logger info r f about to train +num iterations+ iterations sometimes resetting optimizer helps to find a better parameter setting reset = 0 reset < d e f a u l t n u m r e s e t s + 1 reset++ i = 0 i < num iterations i++ converged = bfgs optimize 1 iteration++ logger info r f finished one iteration maximizer i= +i run evaluators illegal argument e e print stack trace logger info catching saying converged converged = e e print stack trace logger info catching saying converged converged = converged logger info r f training has converged i= +i bfgs reset converged optimizer get optimizer bfgs 