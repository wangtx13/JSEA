types pipe pipe iterator io reads through a single breaking each line into data and optional name and label fields bulk loader command option input = command option bulk loader input f i l e containing data one instance per line command option output = command option bulk loader output f i l e data write instance list to command option preserve = command option bulk loader preserve t r u e| f a l s e not force all strings to lowercase command option remove stop words = command option bulk loader remove stopwords t r u e| f a l s e remove \ stop words\ from text option a minimal english stoplist command option stoplist = command option bulk loader stoplist f i l e read newline separated words from and remove them from text option english stoplist triggered remove stopwords command option keep sequence = command option bulk loader keep sequence t r u e| f a l s e data will be a feature sequence rather than a feature vector command option line regex = command option bulk loader line regex r e g e x ^ ^\ \ ^\ \ regular expression containing regex groups label name and data command option name group = command option bulk loader name i n t e g e r 1 index group containing instance name use 0 to indicate that field not used command option label group = command option bulk loader label i n t e g e r 2 index group containing label use 0 to indicate that field not used command option data group = command option bulk loader data i n t e g e r 3 index group containing data command option prune count = command option bulk loader prune count n 0 reduce features to those that occur more than n times command option doc proportion cutoff = command option bulk loader prune doc frequency n 1 0 remove features that occur in more than x 100 % documents 0 05 equivalent to f 3 0 read data from input then write all words that not occur <tt>prune count value< tt> times or more to pruned word pruned tokenizer tokenizer that will be used to write instances generate stoplist simple tokenizer pruned tokenizer i o csv iterator reader = csv iterator reader input value line regex value data group value label group value name group value list< pipe> pipes = list< pipe> alphabet alphabet = alphabet sequence lowercase csl = sequence lowercase simple tokenizer st = pruned tokenizer deep clone list2 feature sequence sl2fs = list2 feature sequence alphabet feature count pipe feature counter = feature count pipe alphabet feature doc freq pipe doc counter = feature doc freq pipe alphabet ! preserve value pipes add csl pipes add st pipes add sl2fs prune count value > 0 pipes add feature counter doc proportion cutoff value < 1 0 pipes add doc counter pipe serial pipe = serial pipes pipes iterator< instance> iterator = serial pipe iterator from reader count = 0 we aren t really interested in instance itself just total feature counts iterator has next count++ count % 100000 == 0 out count iterator next prune count value > 0 feature counter add pruned words to stoplist pruned tokenizer prune count value doc proportion cutoff value < 1 0 doc counter add pruned words to stoplist pruned tokenizer doc proportion cutoff value write instance list simple tokenizer pruned tokenizer i o csv iterator reader = csv iterator reader input value line regex value data group value label group value name group value list< pipe> pipes = list< pipe> alphabet alphabet = alphabet sequence lowercase csl = sequence lowercase list2 feature sequence sl2fs = list2 feature sequence alphabet ! preserve value pipes add csl pipes add pruned tokenizer pipes add sl2fs pipe serial pipe = serial pipes pipes instance list instances = instance list serial pipe instances add thru pipe reader instances save output value i o process command line options command option set summary bulk loader efficient tool importing large amounts text into format command option process bulk loader simple tokenizer tokenizer = stoplist value != tokenizer = simple tokenizer stoplist value remove stop words value tokenizer = simple tokenizer simple tokenizer u s e d e f a u l t e n g l i s h s t o p l i s t tokenizer = simple tokenizer simple tokenizer u s e e m p t y s t o p l i s t prune count value > 0 || doc proportion cutoff value < 1 0 generate stoplist tokenizer write instance list tokenizer 