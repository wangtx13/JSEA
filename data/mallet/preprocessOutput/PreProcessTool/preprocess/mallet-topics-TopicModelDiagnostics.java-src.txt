topics io text types gnu trove topic model diagnostics num topics num top words t w o p e r e n t i n d e x = 1 f i f t y p e r e n t i n d e x = 6 d e f a u l t d o p r o p o r t i o n s = 0 01 0 02 0 05 0 1 0 2 0 3 0 5 all words in sorted order counts list< tree set< sorter>> topic sorted words top n words in each topic in an easy access topic top words list< topic scores> diagnostics parallel topic model model alphabet alphabet topic codocument matrices num rank1 documents num non zero documents num documents at proportions quantity used in entropy calculation sum count times log count word type counts num tokens = 0 topic model diagnostics parallel topic model model num top words num topics = model get num topics num top words = num top words model = model alphabet = model get alphabet topic sorted words = model get sorted words topic top words = num topics num top words num rank1 documents = num topics num non zero documents = num topics num documents at proportions = num topics d e f a u l t d o p r o p o r t i o n s length sum count times log count = num topics diagnostics = list< topic scores> topic = 0 topic < num topics topic++ position = 0 tree set< sorter> sorted words = topic sorted words get topic how many words should we report? some topics may have fewer than number words non zero weight limit = num top words sorted words size < num top words limit = sorted words size iterator< sorter> iterator = sorted words iterator i=0 i < limit i++ sorter info = iterator next topic top words topic i = alphabet lookup info get collect document statistics diagnostics add get tokens per topic model tokens per topic diagnostics add get document entropy model tokens per topic diagnostics add get word length scores diagnostics add get coherence diagnostics add get distance from uniform diagnostics add get distance from corpus diagnostics add get effective number words diagnostics add get token document discrepancies diagnostics add get rank1 percent diagnostics add get document percent ratio f i f t y p e r e n t i n d e x t w o p e r e n t i n d e x diagnostics add get document percent 5 diagnostics add get exclusivity collect document statistics topic codocument matrices = num topics num top words num top words word type counts = alphabet size num tokens = 0 an hash sets containing words interest each topic used checking word at some position one those words t hash set topic top word indices = t hash set num topics same topic top words but indices instead strings used iterating over positions topic word indices in order = num topics num top words an hash sets that will hold words interest present in a document which will be cleared after every document t hash set doc topic word indices = t hash set num topics num docs = model get data size count each topic again cleared after every document topic counts = num topics topic = 0 topic < num topics topic++ t hash set word indices = t hash set i = 0 i < num top words i++ topic top words topic i != type = alphabet lookup index topic top words topic i topic word indices in order topic i = type word indices add type topic top word indices topic = word indices doc topic word indices topic = t hash set doc = 0 topic assignment document model get data feature sequence tokens = feature sequence document instance get data feature sequence topics = feature sequence document topic sequence position = 0 position < tokens size position++ type = tokens get index at position position topic = topics get index at position position num tokens++ word type counts type ++ topic counts topic ++ topic top word indices topic contains type doc topic word indices topic add type doc length = tokens size doc length > 0 max topic = 1 max count = 1 topic = 0 topic < num topics topic++ topic counts topic > 0 num non zero documents topic ++ topic counts topic > max count max topic = topic max count = topic counts topic sum count times log count topic += topic counts topic math log topic counts topic proportion = model alpha topic + topic counts topic model alpha sum + doc length i = 0 i < d e f a u l t d o p r o p o r t i o n s length i++ proportion < d e f a u l t d o p r o p o r t i o n s i num documents at proportions topic i ++ t hash set supported words = doc topic word indices topic indices = topic word indices in order topic i = 0 i < num top words i++ supported words contains indices i j = i j < num top words j++ i == j diagonals are total number documents word w in topic t topic codocument matrices topic i i ++ supported words contains indices j topic codocument matrices topic i j ++ topic codocument matrices topic j i ++ doc topic word indices topic clear topic counts topic = 0 max topic > 1 num rank1 documents max topic ++ doc++ get codocument matrix topic topic codocument matrices topic topic scores get tokens per topic tokens per topic topic scores scores = topic scores tokens num topics num top words topic = 0 topic < num topics topic++ scores set topic score topic tokens per topic topic scores topic scores get document entropy tokens per topic topic scores scores = topic scores document entropy num topics num top words topic = 0 topic < num topics topic++ scores set topic score topic sum count times log count topic tokens per topic topic + math log tokens per topic topic scores topic scores get distance from uniform tokens per topic = model tokens per topic topic scores scores = topic scores uniform dist num topics num top words scores word scores defined = num types = alphabet size topic = 0 topic < num topics topic++ topic score = 0 0 position = 0 tree set< sorter> sorted words = topic sorted words get topic sorter info sorted words type = info get count = info get weight score = count tokens per topic topic math log count num types tokens per topic topic position < num top words scores set topic word score topic position score topic score += score position++ scores set topic score topic topic score scores topic scores get effective number words tokens per topic = model tokens per topic topic scores scores = topic scores eff num words num topics num top words num types = alphabet size topic = 0 topic < num topics topic++ sum squared probabilities = 0 0 tree set< sorter> sorted words = topic sorted words get topic sorter info sorted words type = info get probability = info get weight tokens per topic topic sum squared probabilities += probability probability scores set topic score topic 1 0 sum squared probabilities scores low quality topics may be very similar to global topic scores get distance from corpus tokens per topic = model tokens per topic topic scores scores = topic scores corpus dist num topics num top words scores word scores defined = topic = 0 topic < num topics topic++ coefficient = num tokens tokens per topic topic topic score = 0 0 position = 0 tree set< sorter> sorted words = topic sorted words get topic sorter info sorted words type = info get count = info get weight score = count tokens per topic topic math log coefficient count word type counts type position < num top words out alphabet lookup type + + count + + num tokens + + word type counts type + + tokens per topic topic + = + coefficient count word type counts type scores set topic word score topic position score topic score += score position++ scores set topic score topic topic score scores topic scores get token document discrepancies topic scores scores = topic scores token doc diff num topics num top words scores word scores defined = topic = 0 topic < num topics topic++ matrix = topic codocument matrices topic tree set< sorter> sorted words = topic sorted words get topic topic score = 0 0 word = num top words doc = num top words word sum = 0 0 doc sum = 0 0 position = 0 iterator< sorter> iterator = sorted words iterator iterator has next position < num top words sorter info = iterator next word position = info get weight doc position = matrix position position word sum += word position doc sum += doc position position++ position = 0 position < num top words position++ p = word position word sum q = doc position doc sum mean prob = 0 5 p + q score = 0 0 p > 0 score += 0 5 p math log p mean prob q > 0 score += 0 5 q math log q mean prob scores set topic word score topic position score topic score += score scores set topic score topic topic score scores low quality topics often have lots unusually words topic scores get word length scores topic scores scores = topic scores word length num topics num top words scores word scores defined = topic = 0 topic < num topics topic++ total = 0 position = 0 position < topic top words topic length position++ topic top words topic position == length = topic top words topic position length total += length scores set topic word score topic position length scores set topic score topic total topic top words topic length scores low quality topics often have lots unusually words topic scores get word length standard deviation topic scores scores = topic scores word length sd num topics num top words scores word scores defined = get mean length mean length = 0 0 total words = 0 topic = 0 topic < num topics topic++ position = 0 position < topic top words topic length position++ some topics may not have all n words topic top words topic position == mean length += topic top words topic position length total words ++ mean length = total words now calculate standard deviation length variance = 0 0 topic = 0 topic < num topics topic++ position = 0 position < topic top words topic length position++ topic top words topic position == length = topic top words topic position length length variance += length mean length length mean length length variance = total words 1 produce an overall topic score length s d = math sqrt length variance topic = 0 topic < num topics topic++ position = 0 position < topic top words topic length position++ topic top words topic position == length = topic top words topic position length scores add to topic score topic length mean length length s d scores set topic word score topic position length mean length length s d scores topic scores get coherence topic scores scores = topic scores coherence num topics num top words scores word scores defined = topic = 0 topic < num topics topic++ matrix = topic codocument matrices topic topic score = 0 0 row = 0 row < num top words row++ row score = 0 0 min score = 0 0 col = 0 col < row col++ score = math log matrix row col + model beta matrix col col + model beta row score += score score < min score min score = score topic score += row score scores set topic word score topic row min score scores set topic score topic topic score scores topic scores get rank1 percent topic scores scores = topic scores rank 1 docs num topics num top words topic = 0 topic < num topics topic++ scores set topic score topic num rank1 documents topic num non zero documents topic scores topic scores get document percent ratio numerator index denominator index topic scores scores = topic scores allocation ratio num topics num top words numerator index > num documents at proportions 0 length || denominator index > num documents at proportions 0 length err invalid proportion indices max + num documents at proportions 0 length 1 + + numerator index + + denominator index scores topic = 0 topic < num topics topic++ scores set topic score topic num documents at proportions topic numerator index num documents at proportions topic denominator index scores topic scores get document percent i topic scores scores = topic scores allocation count num topics num top words i > num documents at proportions 0 length err invalid proportion indices max + num documents at proportions 0 length 1 + + i scores topic = 0 topic < num topics topic++ scores set topic score topic num documents at proportions topic i num non zero documents topic scores low quality topics may have words that are also prominent in other topics topic scores get exclusivity tokens per topic = model tokens per topic topic scores scores = topic scores exclusivity num topics num top words scores word scores defined = sum probs = 0 0 topic = 0 topic < num topics topic++ sum probs += model beta model beta sum + tokens per topic topic topic = 0 topic < num topics topic++ topic score = 0 0 position = 0 tree set< sorter> sorted words = topic sorted words get topic sorter info sorted words type = info get count = info get weight sum type probs = sum probs topic counts = model type topic counts type index = 0 index < topic counts length topic counts index > 0 other topic = topic counts index model topic mask other count = topic counts index >> model topic bits we ve already accounted smoothing parameter now we need to add actual count non zero topics sum type probs += other count model beta sum + tokens per topic other topic index++ score = model beta + count model beta sum + tokens per topic topic sum type probs scores set topic word score topic position score topic score += score position++ position == num top words scores set topic score topic topic score num top words scores to builder out = builder formatter formatter = formatter out locale u s topic = 0 topic < num topics topic++ formatter format topic %d topic topic scores scores diagnostics formatter format %s=% 4f scores name scores scores topic formatter format position = 0 position < topic top words topic length position++ topic top words topic position == formatter format %s topic top words topic position topic scores scores diagnostics scores word scores defined formatter format %s=% 4f scores name scores topic word scores topic position out append out to to xml tokens per topic = model tokens per topic builder out = builder formatter formatter = formatter out locale u s out append <?xml version=\ 1 0\ encoding=\ u t f 8\ ?> out append <model> topic = 0 topic < num topics topic++ matrix = topic codocument matrices topic formatter format <topic id= %d topic topic scores scores diagnostics formatter format %s= % 4f scores name scores scores topic out append > tree set< sorter> sorted words = topic sorted words get topic how many words should we report? some topics may have fewer than number words non zero weight limit = num top words sorted words size < num top words limit = sorted words size cumulative probability = 0 0 iterator< sorter> iterator = sorted words iterator position=0 position < limit position++ sorter info = iterator next probability = info get weight tokens per topic topic cumulative probability += probability formatter format <word rank= %d count= % 0f prob= % 5f cumulative= % 5f docs= %d position+1 info get weight probability cumulative probability matrix position position topic scores scores diagnostics scores word scores defined formatter format %s= % 4f scores name scores topic word scores topic position formatter format >%s< word> topic top words topic position replace all amp replace all < out append < topic> out append < model> out to topic scores name scores topic word scores some diagnostics have meaningful values each word others not word scores defined = topic scores name num topics num words name = name scores = num topics topic word scores = num topics num words set topic score topic score scores topic = score add to topic score topic score scores topic += score set topic word score topic word position score topic word scores topic word position = score word scores defined = instance list instances = instance list load 0 num topics = parse 1 parallel topic model model = parallel topic model num topics 5 0 0 01 model add instances instances model set num iterations 1000 model estimate topic model diagnostics diagnostics = topic model diagnostics model 20 length == 3 print writer out = print writer 2 out diagnostics to xml out close 