2009 m a l l e t m achine languag e ~mccallum 1 0 further ` l i e n s e semi supervised io serializable logging logger types feature vector sequence types instance list r f sum lattice sum lattice transducer optimize optimizable logger a r f objective function that entropy r f s predictions on unlabeled data references feng jiao shaojun wang chi hoon lee russell greiner dale schuurmans semi supervised conditional random fields improved sequence segmentation and labeling a l 2006 gideon mann andrew mc callum efficient computation entropy gradient semi supervised conditional random fields h l t n a a l 2007 author gaurav chandalia author gregory druck r f optimizable entropy regularization optimizable gradient value serializable logger logger = logger get logger r f optimizable entropy regularization get name cached value weights stamp = 1 cached gradient weights stamp = 1 model s expectations according to entropy reg r f factors expectations used to update gradient transducer incrementor incrementor contains labeled and unlabeled data instance list data model r f crf scale entropy values typically entropy reg gamma num labeled num unlabeled scaling factor log probability all sequences also entropy due to all instances updated in compute expectations cached value gradient due to optimizable updated in get value gradient cached gradient initializes structures r f optimizable entropy regularization r f crf instance list ilist scaling factor data = ilist crf = crf scaling factor = scaling factor initialize expectations using model expectations = r f factors crf incrementor = expectations incrementor cached value = 0 0 cached gradient = crf get get num factors initializes structures sets scaling factor to 1 0 r f optimizable entropy regularization r f crf instance list ilist crf ilist 1 0 get scaling factor scaling factor set scaling factor scaling factor scaling factor = scaling factor resets computes and fills expectations from all instances also updating entropy value <p> analogous to <tt> r f optimizable label likelihood get expectation value<tt> compute expectations expectations zero now update expectations due to each instance entropy reg ii = 0 ii < data size ii++ feature vector sequence input = feature vector sequence data get ii get data sum lattice lattice = sum lattice crf input udpate expectations entropy lattice entropy lattice = entropy lattice input lattice get gammas lattice get xis crf incrementor scaling factor cached value += entropy lattice get entropy get value crf get weights value change stamp != cached value weights stamp cached value not up to date it was calculated a different set r f weights cached value weights stamp = crf get weights value change stamp cached value = 0 compute expectations cached value = scaling factor cached value ! na n cached value ! infinite cached value likelihood due to entropy regularization na n infinite logger info get value entropy regularization = + cached value cached value get value gradient buffer cached gradient weights stamp != crf get weights value change stamp cached gradient weights stamp = crf get weights value change stamp cached gradient will soon no longer be stale get value fails then look in compute expectations expectations not na n or infinite fill up gradient expectations get cached gradient arraycopy cached gradient 0 buffer 0 cached gradient length some get set that have to be get num crf get get num factors get buffer crf get get buffer set buffer crf get set buffer crf weights value changed get parameter index crf get get parameter index set parameter index value crf get set parameter index value crf weights value changed serialization stuff serial u = 1 