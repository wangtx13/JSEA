2002 m a l l e t m achine languag e ~mccallum 1 0 further ` l i e n s e author andrew mc callum <a href= mailto >mccallum edu< a> extract io output stream io input stream io i o types token sequence sequence lexer tokenization token sequence tokenization sequence document create an empty tokenization tokenization sequence seq document = seq creates a tokenization given tokens are added from all matches given lexer tokenization sequence sequence lexer lexer document = lexer set sequence lexer has next lexer next add span lexer get start offset lexer get end offset xxx refactor into tokenization span subspan first token last token span first span = span get first token start idx = first span get start idx end idx last token > size end idx = document length span last span = span get last token 1 end idx = last span get end idx span document start idx end idx span get span i span get i get document document serialization garbage serial u = 1 u r r e n t s e r i a l v e r s i o n = 1 write output stream out i o out write out write u r r e n t s e r i a l v e r s i o n read input stream in i o not found in read = in read 