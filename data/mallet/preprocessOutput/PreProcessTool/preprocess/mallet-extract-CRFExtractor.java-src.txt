2003 m a l l e t m achine languag e ~mccallum 1 0 further ` l i e n s e extract io list iterator r f pipe noop pipe pipe pipe serial pipes types created oct 12 2004 author < a h r e f= mailto casutton edu>casutton edu< a> $ r f extractor v 1 1 2007 10 22 21 37 44 exp $ r f extractor extractor r f crf pipe tokenization pipe pipe feature pipe background tag tokenization filter filter r f extractor r f crf crf noop r f extractor crf i o load crf crf noop r f extractor r f crf pipe tokpipe crf tokpipe b i o tokenization filter r f extractor r f crf pipe tokpipe tokenization filter filter crf tokpipe filter o r f extractor r f crf pipe tokpipe tokenization filter filter background tag crf = crf tokenization pipe = tokpipe feature pipe = pipe crf get input pipe filter = filter background tag = background tag r f load crf crf i o input stream ois = input stream input stream crf r f crf = we shouldn t run into a not found crf = r f ois read not found e err internal m a l l e t could not read r f from +crf file+ +e e print stack trace runtime e ois close crf extraction extract o i t think there s a polymorphic way to b sucks cas o tokenization extract tokenization o o instance list extract instance list o extract tokenize o tokenization tokenize obj instance toked = instance obj tokenization pipe pipe toked tokenization toked get data extraction extract tokenization spans we assume input unpiped instance carrier = feature pipe pipe instance spans sequence output = crf transduce sequence carrier get data extraction extraction = extraction get target alphabet document extraction docseq = document extraction extraction get target alphabet spans output background tag filter extraction add document extraction docseq extraction instance list pipe instances iterator< instance> source i think that pipes should be associated neither instance lists nor instances cas instance list toked = instance list tokenization pipe toked add thru pipe source instance list piped = instance list get feature pipe piped add thru pipe toked iterator piped assumes instance source contains tokenization extraction extract instance list ilist extraction extraction = extraction get target alphabet i = 0 i < ilist size i++ instance inst = ilist get i tokenization tok = tokenization inst get source name = inst get name to sequence input = sequence inst get data sequence target = sequence inst get target sequence output = crf transduce input document extraction docseq = document extraction name get target alphabet tok output target background tag filter extraction add document extraction docseq extraction extraction extract iterator< instance> source extraction extraction = extraction get target alphabet put all instances through both pipes then get viterbi path instance list toked list = instance list tokenization pipe toked list add thru pipe source instance list piped list = instance list get feature pipe piped list add thru pipe toked list iterator iterator< instance> it1 = toked list iterator iterator< instance> it2 = piped list iterator it1 has next instance toked = it1 next instance piped = it2 next tokenization tok = tokenization toked get data name = piped get name to sequence input = sequence piped get data sequence target = sequence piped get target sequence output = crf transduce input document extraction docseq = document extraction name get target alphabet tok output target background tag filter extraction add document extraction docseq extraction tokenization filter get tokenization filter filter get background tag background tag pipe get tokenization pipe tokenization pipe set tokenization pipe pipe tokenization pipe tokenization pipe = tokenization pipe pipe get feature pipe feature pipe xxx inherent dangerous!!! should check that pipe alphabet equals crf alphabet set feature pipe pipe feature pipe feature pipe = feature pipe alphabet get input alphabet crf get input alphabet label alphabet get target alphabet label alphabet crf get output alphabet r f get crf crf transfer some pipes from feature pipe to tokenization pipe feature pipe must be a serial pipes will destructively modify r f extractor useful you have a r f hat has been trained from a single pipe which you need to split up feature and tokenization pipes slice pipes num pipe fpipe = get feature pipe ! fpipe serial pipes illegal argument slice pipes feature pipe must be a serial pipes serial pipes sp = serial pipes fpipe list pipes = list i = 0 i < num i++ pipes add sp get pipe 0 sp remove pipe 0 t o d o fix set tokenization pipe sp t o d o fix unsupported operation not yet serialization nonsense serial 0 initial serial 1 add feature pipe serial 2 add filter u r r e n t s e r i a l v e r s i o n = 2 serial u = 1 read input stream in i o not found in read = in read == 0 || feature pipe == feature pipe = pipe crf get input pipe < 2 filter = b i o tokenization filter write output stream out i o out write out write u r r e n t s e r i a l v e r s i o n sequence pipe input input instance list all = instance list get feature pipe all add input sequence all get 0 get data 