2002 m a l l e t m achine languag e ~mccallum 1 0 further ` l i e n s e types awt geom point2 d list arrays collections comparator hashtable iterator logging logger logger maths list features along their thresholds sorted in descending order ratio 1 gained splitting instances on feature at its associated threshold value to 2 split <p> calculations performed not take into consideration instance weights <p> to create an instance gain ratio from an instance list one must following <p><tt> instance list ilist = gain ratio gr = gain ratio create gain ratio ilist < tt><p> j r quinlan improved use continuous attributes in c4 5 ftp ftp cmu project jair volume4 quinlan96a ps author gary huang <a href= mailto ghuang >ghuang edu< a> gain ratio ranked feature vector logger logger = logger get logger gain ratio get name serial u = 1 l log2 = math log 2 m split points m base entropy label vector m base label m num split points best feature m min num insts calculates gain ratios all feature split point pairs snd <pre> 1 gain ratios each element max gain ratio a feature those split points at least average gain 2 optimal split point each feature 3 overall entropy 4 overall label given instances 5 number split points split feature < pre> calc gain ratios instance list ilist inst indices min num insts num insts = inst indices length alphabet data dict = ilist get data alphabet label alphabet target dict = label alphabet ilist get target alphabet target counts = target dict size accumulate target label counts and make sure sum each instance s target label 1 ii = 0 ii < num insts ii++ instance inst = ilist get inst indices ii labeling labeling = inst get labeling label weight sum = 0 ll = 0 ll < labeling num locations ll++ = labeling index at location ll label weight = labeling value at location ll label weight sum += label weight target counts += label weight maths almost equals label weight sum 1 calculate base entropy info d and label given instances target = target dict size base entropy = 0 ci = 0 ci < target dict size ci++ p = target counts ci num insts target ci = p p > 0 base entropy = p math log p log2 label vector base label = label vector target dict target info gain sum = 0 total num split points = 0 pass test target counts = target dict size maps feature index > hashtable and each table maps split point > info gain split ratio hashtable feature to info = hashtable data dict size go through each feature s split points in ascending order fi = 0 fi < data dict size fi++ fi+1 % 1000 == 0 logger info at feature + fi+1 + + data dict size feature to info fi = hashtable arrays fill pass test target counts 0 sort instances on feature s values inst indices = sort instances ilist inst indices fi iterate through sorted instances ii = 0 ii < num insts 1 ii++ instance inst = ilist get inst indices ii instance inst plus one = ilist get inst indices ii+1 feature vector fv1 = feature vector inst get data feature vector fv2 = feature vector inst plus one get data lower = fv1 value fi higher = fv2 value fi accumulate label weights instances passing test labeling labeling = inst get labeling ll = 0 ll < labeling num locations ll++ = labeling index at location ll label weight = labeling value at location ll pass test target counts += label weight maths almost equals lower higher || inst get labeling to equals inst plus one get labeling to feature spilt point pair calculate info gain using pair to split insts into those value feature <= p versus > p total num split points++ split point = lower + higher 2 num pass insts = ii+1 split point creates a partition too few instances ignore it num fail insts = num insts num pass insts num pass insts < min num insts || num fail insts < min num insts all instances pass or fail test it useless pass proportion = num pass insts num insts maths almost equals pass proportion 0 || maths almost equals pass proportion 1 calculate entropy instances passing and failing test pass entropy = 0 fail entropy = 0 p ci = 0 ci < target dict size ci++ num pass insts > 0 p = pass test target counts ci num pass insts p > 0 pass entropy = p math log p log2 num fail insts > 0 fail test target count = target counts ci pass test target counts ci p = fail test target count num fail insts p > 0 fail entropy = p math log p log2 calculate gain d t gained testing on feature split point pair gain d t = base entropy pass proportion pass entropy 1 pass proportion fail entropy info gain sum += gain d t calculate split d t split split d t = pass proportion math log pass proportion log2 1 pass proportion math log 1 pass proportion log2 calculate gain ratio gain ratio = gain d t split d t feature to info fi put split point point2 d gain d t gain ratio end loop through sorted instances end loop through features each feature s split point at least average gain get maximum gain ratio and associated split point using info gain tie breaker gain ratios = data dict size split points = data dict size num splits best feature = 0 all feature vectors are identical or no splits are worthy all 0s total num split points == 0 || maths almost equals info gain sum 0 gain ratios split points base entropy base label num splits best feature avg info gain = info gain sum total num split points max gain ratio = 0 gain max gain ratio = 0 tie breaker xxx = 0 fi = 0 fi < data dict size fi++ feature max gain ratio = 0 feature gain max gain ratio = 0 best split point = na n iterator iter = feature to info fi key set iterator iter has next key = iter next point2 d pt = point2 d feature to info fi get key split point = key value info gain = pt get x gain ratio = pt get y info gain >= avg info gain gain ratio > feature max gain ratio || gain ratio == feature max gain ratio info gain > feature gain max gain ratio feature max gain ratio = gain ratio feature gain max gain ratio = info gain best split point = split point xxx++ best split point != na n gain ratios fi = feature max gain ratio split points fi = best split point feature max gain ratio > max gain ratio || feature max gain ratio == max gain ratio feature gain max gain ratio > gain max gain ratio max gain ratio = feature max gain ratio gain max gain ratio = feature gain max gain ratio num splits best feature = feature to info fi size logger info label distrib + base label logger info base entropy= + base entropy + info gain sum= + info gain sum + total num split points= + total num split points + avg info gain= + avg info gain + num splits < avg gain= + xxx gain ratios split points base entropy base label num splits best feature sort instances instance list ilist inst indices feature index list list = list ii = 0 ii < inst indices length ii++ instance inst = ilist get inst indices ii feature vector fv = feature vector inst get data list add point2 d inst indices ii fv value feature index collections sort list comparator compare o1 o2 point2 d p1 = point2 d o1 point2 d p2 = point2 d o2 p1 y == p2 y p1 x != p2 x p1 x > p2 x ? 1 1 p1 y > p2 y ? 1 1 sorted = inst indices length i = 0 i < list size i++ sorted i = point2 d list get i get x sorted constructs a gain ratio gain ratio create gain ratio instance list ilist inst indices = ilist size ii = 0 ii < inst indices length ii++ inst indices ii = ii create gain ratio ilist inst indices 2 constructs a gain ratio gain ratio create gain ratio instance list ilist inst indices min num insts objs = calc gain ratios ilist inst indices min num insts gain ratios = objs 0 split points = objs 1 base entropy = objs 2 value label vector base label = label vector objs 3 num split points best feature = objs 4 value gain ratio ilist get data alphabet gain ratios split points base entropy base label num split points best feature min num insts gain ratio alphabet data alphabet gain ratios split points base entropy label vector base label num split points best feature min num insts data alphabet gain ratios m split points = split points m base entropy = base entropy m base label = base label m num split points best feature = num split points best feature m min num insts = min num insts threshold feature threshold pair maximum gain ratio get max valued threshold get threshold at rank 0 threshold feature threshold pair given rank get threshold at rank rank index = get index at rank rank m split points index get base entropy m base entropy label vector get base label m base label get num split points best feature m num split points best feature 