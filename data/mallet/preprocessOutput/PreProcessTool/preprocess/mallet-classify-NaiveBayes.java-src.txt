2002 m a l l e t m achine languag e ~mccallum 1 0 further ` l i e n s e classify io output stream io input stream io serializable io i o arrays classify classifier pipe pipe types types multinomial logged a classifier that classifies instances according to naive bayes in an bayes classifier p classification| data = p data| classification p classification p data <p> to compute likelihood <br> p data| classification = p d1 d2 dn | classification <br> naive bayes makes assumption that all data are conditionally independent given classification <br> p d1 d2 dn | classification = p d1| classification p d2| classification <br> <p> other classifiers in naive bayes two classes a trainer and a classifier link classify naive bayes trainer produces estimates various p dn| classifier and contructs those estimates <p> instances are assumed to be link types feature vector s <p> other classifiers classification may only be performed on instances processed pipe associated classifer ie naive bayes get pipe instance naive bayes trainer sets pipe to pipe used to process training instances <p> a naive bayes classifier can be persisted and reused using serialization naive bayes trainer feature vector author andrew mc callum <a href= mailto >mccallum edu< a> naive bayes classifier serializable multinomial logged prior multinomial logged p construct a naive bayes classifier from a pipe prior estimates each classification and feature estimates each classification a naive bayes classifier generally generated from a naive bayes trainer not constructed directly users proability estimates are converted and saved logarithms internally instance pipe used to check that feature vector dictionary each instance same that associated pipe suppresses check prior mulinomial that gives an estimate prior probability each classification index2 feature prob an multinomials giving an estimate probability a classification each feature each featurevector naive bayes pipe instance pipe multinomial logged prior multinomial logged index2 feature prob instance pipe prior = prior p = index2 feature prob multinomial logged log multinomials multinomial m multinomial logged ml = multinomial logged m length i = 0 i < m length i++ ml i = multinomial logged m i ml construct a naive bayes classifier from a pipe prior estimates each classification and feature estimates each classification a naive bayes classifier generally generated from a naive bayes trainer not constructed directly users data pipe used to check that feature vector dictionary each instance same that associated pipe suppresses check prior mulinomial that gives an estimate prior probability each classification index2 feature prob an multinomials giving an estimate probability a classification each feature each featurevector naive bayes pipe data pipe multinomial prior multinomial index2 feature prob data pipe multinomial logged prior log multinomials index2 feature prob multinomial logged get multinomials p logged get priors prior print words num to print alphabet alphabet = instance pipe get data alphabet num features = alphabet size num labels = instance pipe get target alphabet size probs = num features num to print = math min num to print num features = 0 < num labels li++ arrays fill probs 0 0 p add probabilities probs ranked feature vector rfv = ranked feature vector alphabet probs out feature probabilities +instance pipe get target alphabet lookup i = 0 i < num to print i++ out rfv get at rank i + +rfv get value at rank i classify an instance using naive bayes according to trained data alphabet feature vector instance must match alphabe pipe used to train classifier instance to be classified data field must be a feature vector classification containing labeling instance classification classify instance instance note that current size label alphabet can be larger than it was at time training we are careful here to correctly handle those labels here example we assume log prior probability those classes minus infinity num classes = get label alphabet size scores = num classes feature vector fv = feature vector instance get data make sure feature vector s feature dictionary matches what we are expecting from our data pipe and thus our notion feature probabilities instance pipe == || fv get alphabet == instance pipe get data alphabet fvisize = fv num locations prior add log probabilities scores set scores according to feature weights and per probabilities fvi = 0 fvi < fvisize fvi++ fi = fv index at location fvi ci = 0 ci < num classes ci++ guard against data alphabet or target alphabet growing can happen classifying a never before seen feature ignore these ci >= p length || fi >= p ci size scores ci += fv value at location fvi p ci log probability fi get scores in range near zero where exp more accurate max score = n e g a t i v e i n f i n i t y ci = 0 ci < num classes ci++ scores ci > max score max score = scores ci ci = 0 ci < num classes ci++ scores ci = max score exponentiate and normalize sum = 0 ci = 0 ci < num classes ci++ sum += scores ci = math exp scores ci ci = 0 ci < num classes ci++ scores ci = sum create and a classification classification instance label vector get label alphabet scores data log probability instance instance label index feature vector fv = feature vector instance get data fvisize = fv num locations log prob = 0 fvi = 0 fvi < fvisize fvi++ log prob += fv value at location fvi p label index log probability fv index at location fvi log prob data log likelihood instance list ilist log likelihood = 0 ii = 0 ii < ilist size ii++ instance weight = ilist get instance weight ii instance inst = ilist get ii labeling labeling = inst get labeling labeling != log likelihood += instance weight data log probability inst labeling get best index labeling predicted = classify inst get labeling err label = +labeling err predicted = +predicted lpos = 0 lpos < predicted num locations lpos++ = predicted index at location lpos label weight = predicted value at location lpos err print +label weight label weight == 0 log likelihood += instance weight label weight data log probability inst log likelihood label log likelihood instance list ilist log likelihood = 0 ii = 0 ii < ilist size ii++ instance weight = ilist get instance weight ii instance inst = ilist get ii labeling labeling = inst get labeling labeling == labeling predicted = classify inst get labeling err label = +labeling err predicted = +predicted labeling num locations == 1 log likelihood += instance weight math log predicted value labeling get best index lpos = 0 lpos < labeling num locations lpos++ = labeling index at location lpos label weight = labeling value at location lpos err print +label weight label weight == 0 log likelihood += instance weight label weight math log predicted value log likelihood serialization serial u overriden to prevent innocuous changes in from making serialization mechanism think external format has changed serial u = 1 u r r e n t s e r i a l v e r s i o n = 1 write output stream out i o out write u r r e n t s e r i a l v e r s i o n out write get instance pipe write prior each out write prior write conditional probability estimates out write p read input stream in i o not found = in read != u r r e n t s e r i a l v e r s i o n not found mismatched naive bayes versions wanted + u r r e n t s e r i a l v e r s i o n + got + instance pipe = pipe in read prior = multinomial logged in read p = multinomial logged in read 