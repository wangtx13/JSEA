2003 m a l l e t m achine languag e ~mccallum 1 0 further ` l i e n s e types optimize optimizable types instance types instance list types sparse vector logger caching optimizable gnu trove t hash map io output stream io i o io print stream io serializable list bit set iterator list logging logger created mar 15 2005 author < a h r e f= mailto casutton edu>casutton edu< a> $ pseudolikelihood a r f trainer v 1 1 2007 10 22 21 37 40 exp $ pseudolikelihood a r f trainer acrf trainer logger logger = logger get logger pseudolikelihood a r f trainer get name print gradient = use per variable pseudolikelihood classical besag b y v a r i a b l e = 0 use per edge structured pseudolikelihood b y e d g e = 1 structure type = b y v a r i a b l e get structure type structure type set structure type structure type structure type = structure type optimizable gradient value create optimizable a r f acrf instance list training maxable acrf training controls structuredness pl cliques iterator has next advance factor local conditional a r f unrolled var set cliques variables iterator cliques iterator a r f unrolled graph graph assignment observed cursors vidx = 1 factor ptl list cliques var variables iterator a r f unrolled graph acrf assignment observed graph = acrf observed = observed cliques var = list graph num variables i = 0 i < cliques var length i++ cliques var i = list iterator it = acrf unrolled var set iterator it has next a r f unrolled var set clique = a r f unrolled var set it next vidx = 0 vidx < clique size vidx++ variable var = clique get vidx cliques var graph get index var add clique has next vidx < graph num variables 1 advance vidx++ variable var = graph get vidx ptl = table factor var iterator it = cliques var vidx iterator it has next a r f unrolled var set clique = a r f unrolled var set it next factor clique ptl = graph factor clique clique ptl == illegal state could not find potential clique +clique var set vs = hash var set clique ptl var set vs remove var assignment nbr assn = assignment observed marginalize vs factor slice = clique ptl slice nbr assn ptl multiply slice factor local conditional ptl a r f unrolled var set cliques list cliques = cliques var vidx a r f unrolled var set cliques to a r f unrolled var set cliques size edges iterator cliques iterator a r f unrolled graph graph assignment observed cursors iterator cursor list current clique list factor ptl t hash map cliques edge edges iterator a r f unrolled graph acrf assignment observed graph = acrf observed = observed cliques edge = t hash map iterator it = acrf unrolled var set iterator it has next a r f unrolled var set clique = a r f unrolled var set it next v1idx = 0 v1idx < clique size v1idx++ variable v1 = clique get v1idx list adjlist = graph all factors containing v1 iterator factor it = adjlist iterator factor it has next factor factor = factor factor it next !cliques edge contains key factor cliques edge put factor list list l = list cliques edge get factor !l contains clique l add clique cursor = cliques edge key set iterator has next cursor has next advance factor pair factor = factor cursor next var set pair var set = pair factor var set pair var set size == 2 now variable v1 = pair var set get 0 variable v2 = pair var set get 1 variable vars = variable v1 v2 ptl = table factor vars set local obs to assignment to all data e x e p t v1 and v2 var set vs = hash var set observed var set vs remove v1 vs remove v2 assignment local obs = assignment observed marginalize vs current clique list = list cliques edge get pair factor iterator it = current clique list iterator it has next a r f unrolled var set clique = a r f unrolled var set it next factor clique ptl = graph factor clique clique ptl == illegal state could not find potential clique +clique factor slice has v1 = clique contains v1 has v2 = clique contains v2 has v1 has v2 fast special clique ptl var set size == 2 slice = clique ptl slice = clique ptl slice local obs has v1 !has v2 slice = clique ptl slice local obs has v2 !has v1 slice = clique ptl slice local obs runtime illegal state cliqu ehas neither edge variable ptl multiply slice factor local conditional ptl a r f unrolled var set cliques list cliques = current clique list a r f unrolled var set cliques to a r f unrolled var set cliques size cliques iterator make cliques iterator a r f unrolled graph acrf assignment observed structure type == b y v a r i a b l e variables iterator acrf observed structure type == b y e d g e edges iterator acrf observed illegal argument unknown structured pseudolikelihood type +structure type maxable caching optimizable gradient serializable a r f acrf instance list train data a r f template templates a r f template fixed tmpls bit set infinite values = num d e f a u l t g a u s s i a n p r i o r v a r i a n e = 10 0 get gaussian prior variance gaussian prior variance set gaussian prior variance gaussian prior variance gaussian prior variance = gaussian prior variance gaussian prior variance = d e f a u l t g a u s s i a n p r i o r v a r i a n e vectors that contain counts features observed in training data maps clique template x feature number => count sparse vector constraints vectors that contain expected value over labels all features have seen training data but not training labels sparse vector expectations sparse vector constraints sparse vector expectations init weights instance list training ugh!! there must be a way to back into a r f but i t know best way problem that maxable doesn t extend a r f maxiximable so i can t just call its init weights tidx = 0 tidx < templates length tidx++ num += templates tidx init weights training initialize constraints and expectations to have same dimensions weights but to be all zero init constraints expectations defaults first constraints = sparse vector templates length expectations = sparse vector templates length tidx = 0 tidx < templates length tidx++ sparse vector defaults = templates tidx get weights constraints tidx = sparse vector defaults clone matrix zeroed expectations tidx = sparse vector defaults clone matrix zeroed and now others constraints = sparse vector templates length expectations = sparse vector templates length tidx = 0 tidx < templates length tidx++ a r f template tmpl = templates tidx sparse vector weights = tmpl get weights constraints tidx = sparse vector weights length expectations tidx = sparse vector weights length i = 0 i < weights length i++ constraints tidx i = sparse vector weights i clone matrix zeroed expectations tidx i = sparse vector weights i clone matrix zeroed set all expectations to 0 after they ve been initialized reset expectations tidx = 0 tidx < expectations length tidx++ expectations tidx set all 0 0 i = 0 i < expectations tidx length i++ expectations tidx i set all 0 0 maxable a r f acrf instance list ilist logger finest initializing optimizable a r f acrf = acrf templates = acrf get templates fixed tmpls = acrf get fixed templates allocate weights constraints and expectations train data = ilist init weights train data init constraints expectations num instances = train data size cached value stale = cached gradient stale = cache unrolled graphs unrolled graphs = unrolled graph num instances logger info number training instances = + num instances logger info number = + num describe prior logger fine computing constraints collect constraints train data describe prior logger info using gaussian prior variance +gaussian prior variance get num num negate initial value and value because are in weights not values get buf buf length != num illegal argument argument not + correct dimensions idx = 0 tidx = 0 tidx < templates length tidx++ a r f template tmpl = templates tidx sparse vector defaults = tmpl get weights values = defaults get values arraycopy values 0 buf idx values length idx += values length tidx = 0 tidx < templates length tidx++ a r f template tmpl = templates tidx sparse vector weights = tmpl get weights assn = 0 assn < weights length assn++ values = weights assn get values arraycopy values 0 buf idx values length idx += values length set internal params cached value stale = cached gradient stale = idx = 0 tidx = 0 tidx < templates length tidx++ a r f template tmpl = templates tidx sparse vector defaults = tmpl get weights values = defaults get values arraycopy params idx values 0 values length idx += values length tidx = 0 tidx < templates length tidx++ a r f template tmpl = templates tidx sparse vector weights = tmpl get weights assn = 0 assn < weights length assn++ values = weights assn get values arraycopy params idx values 0 values length idx += values length functions unit tests to get constraints and expectations i m too lazy to make a deep copy callers should not modify these sparse vector get expectations cnum expectations cnum sparse vector get constraints cnum constraints cnum print weights print buf = num get buf len = buf length w = 0 w < len w++ out print buf w + out compute value retval = 0 0 num instances = train data size start = current time millis unroll time = 0 instance values must either always or never be in total values we can t just sometimes skip a value because it infinite that off total values we only allow an instance to have infinite value it happens from start we t compute value instance after first round any other instance has infinite value after that it an initializing infinite values = infinite values == we could initialize bitset one slot every instance but it probably cheaper not to taking time hit to allocate space a bit becomes necessary infinite values = bit set initializing infinite values = clear sufficient statistics that we are about to fill reset expectations fill in expectations each instance i = 0 i < num instances i++ instance instance = train data get i compute marginals each clique unroll start = current time millis a r f unrolled graph unrolled = a r f unrolled graph instance templates fixed tmpls unroll end = current time millis unroll time += unroll end unroll start unrolled num variables == 0 happens all nodes are pruned save expected value each feature when we compute gradient assignment observations = unrolled get assignment value = collect expectations and value unrolled observations infinite value initializing infinite values logger warning instance + instance get name + has infinite value skipping infinite values set i !infinite values get i logger warning infinite value on instance +instance get name + returning infinity n e g a t i v e i n f i n i t y print debug info unrolled illegal state instance + instance get name + used to have non infinite + value but now it has infinite value na n value out na n on instance +i+ +instance get name print debug info unrolled illegal state value na n in a r f get value instance +i logger warning value na n in a r f get value instance +i+ + returning infinity n e g a t i v e i n f i n i t y retval += value incorporate gaussian prior on means that each weight we will add w^2 2 variance to log probability prior denom = 2 gaussian prior variance tidx = 0 tidx < templates length tidx++ sparse vector weights = templates tidx get weights j = 0 j < weights length j++ fnum = 0 fnum < weights j num locations fnum++ w = weights j value at location fnum weight valid w tidx j retval += w w prior denom end = current time millis logger info a r f inference time ms = + end start logger info a r f unroll time ms = +unroll time logger info get value loglikelihood = +retval retval computes gradient penalized log likelihood a r f and places it in cached gradient gradient constraint expectation gaussian prior variance compute value gradient grad index into current element cached gradient gidx = 0 first gradient wrt weights tidx = 0 tidx < templates length tidx++ sparse vector these weights = templates tidx get weights sparse vector these constraints = constraints tidx sparse vector these expectations = expectations tidx j = 0 j < these weights num locations j++ weight = these weights value at location j constraint = these constraints value at location j expectation = these expectations value at location j print gradient out gradient +gidx+ = +constraint+ ctr +expectation+ exp + weight gaussian prior variance + reg feature= d e f a u l t grad gidx++ = constraint expectation weight gaussian prior variance now other weights tidx = 0 tidx < templates length tidx++ a r f template tmpl = templates tidx sparse vector weights = tmpl get weights i = 0 i < weights length i++ sparse vector weight vec = weights i sparse vector constraint vec = constraints tidx i sparse vector expectation vec = expectations tidx i j = 0 j < weight vec num locations j++ w = weight vec value at location j gradient computed below constraint = constraint vec value at location j expectation = expectation vec value at location j a parameter may be set to infinity an external user we set gradient to 0 because parameter s value can never change anyway and it will mess up future calculations on matrix infinite w logger warning infinite weight node index +i+ feature + acrf get input alphabet lookup j gradient = 0 0 gradient = constraint w gaussian prior variance expectation print gradient idx = weight vec index at location j fname = acrf get input alphabet lookup idx out gradient +gidx+ = +constraint+ ctr +expectation+ exp + w gaussian prior variance + reg feature= +fname+ grad gidx++ = gradient every feature f k computes expected value f k aver all possible label sequences given list instances we have these values are stored in collector that collector i j k gets expected value feature clique i label assignment j and input features k collect expectations and value a r f unrolled graph unrolled assignment observations value = 0 0 cliques iterator it = make cliques iterator unrolled observations it has next it advance table factor ptl = table factor it local conditional log z = ptl logsum a r f unrolled var set cliques = it cliques assignment assn = assignment observations duplicate each assigment to clique xxx s l o w will need to be sparsified assignment iterator assn it = ptl assignment iterator assn it has next marginal = math exp ptl log value assn it log z ugly need to map from assignments to single twiddled variable to clique assignments assignment current assn = assn it assignment vi = 0 vi < current assn num variables vi++ variable var = current assn get variable vi assn set value 0 var current assn get var cidx = 0 cidx < cliques length cidx++ a r f unrolled var set clique = cliques cidx tidx = clique get template index tidx == 1 assn idx = clique lookup number assignment assn expectations tidx assn idx plus equals sparse clique get fv marginal expectations tidx location assn idx != 1 expectations tidx increment value assn idx marginal assn it advance value += ptl log value observations log z value collect constraints graph a r f unrolled graph unrolled assignment observations cliques iterator it = make cliques iterator unrolled observations it has next it advance a r f unrolled var set cliques = it cliques cidx = 0 cidx < cliques length cidx++ a r f unrolled var set clique = cliques cidx tidx = clique get template index tidx < 0 assn idx = clique lookup number assignment observations constraints tidx assn idx plus equals sparse clique get fv 1 0 constraints tidx location assn idx != 1 constraints tidx increment value assn idx 1 0 collect constraints instance list ilist inum = 0 inum < ilist size inum++ logger finest collecting constraints instance +inum instance inst = ilist get inum a r f unrolled graph unrolled = a r f unrolled graph inst templates assignment assn = unrolled get assignment collect constraints graph unrolled assn dump gradient to name grad = get num get value gradient grad print stream w = print stream output stream name i = 0 i < num i++ w grad i w close i o e err could not open output e print stack trace dump defaults out constraints i = 0 i < constraints length i++ out template +i constraints i print out expectations i = 0 i < expectations length i++ out template +i expectations i print print debug info a r f unrolled graph unrolled acrf print err assignment assn = unrolled get assignment iterator it = unrolled var set iterator it has next a r f unrolled var set clique = a r f unrolled var set it next out clique +clique dump assn clique assn clique factor ptl = unrolled factor clique out value = +ptl value assn out ptl dump assn clique assignment assn a r f unrolled var set clique iterator it = clique iterator it has next variable var = variable it next out var+ ==> +assn get var + +assn get var + weight valid w cnum j infinite w logger warning weight infinite clique +cnum+ assignment +j na n w logger warning weight nan clique +cnum+ assignment +j optimizable a r f 