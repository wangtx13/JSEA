2011 m a l l e t m achine languag e ~mccallum 1 0 further ` l i e n s e classify list bit set hash map logging logger classify classifier classify max ent classify max ent optimizable label classify constraints pr max ent l2 f l p r constraints classify constraints pr max ent p r constraint optimize limited memory b f g s optimize optimizer types instance types instance list types label alphabet types label vector types matrix ops types label logger maths penalty soft posterior regularization p r training max ent author gregory druck <a href= mailto gdruck >gdruck edu< a> max ent p r trainer classifier trainer< max ent> classifier trainer optimization< max ent> logger logger = logger get logger max ent p r trainer get name using from command line normalize = use values = min iterations = 10 max iterations = 500 q g p v constraints converged = num iterations = 0 tolerance = 0 001 p g p v list< max ent p r constraint> constraints max ent p p r aux classifier q max ent p r trainer max ent p r trainer list< max ent p r constraint> constraints constraints = constraints set p gaussian prior variance p g p v p g p v = p g p v set q gaussian prior variance q g p v q g p v = q g p v set constraints filename constraints = filename set use values flag use values = flag set min iterations min iterations min iterations = min iterations set max iterations min iterations max iterations = min iterations set normalize normalize normalize = normalize optimizer get optimizer runtime not yet implemented! get iteration num iterations override finished training converged override max ent get classifier p override max ent train instance list training set train training set max iterations max ent train instance list training set max iterations train training set math min max iterations min iterations max iterations max ent train instance list data min iterations max iterations constraints == constraints != hash map< > constraints map = feature constraint read constraints from constraints data logger info number constraints + constraints map size constraints = list< max ent p r constraint> max ent l2 f l p r constraints pr constraints = max ent l2 f l p r constraints data get data alphabet size data get target alphabet size use values normalize fi constraints map key set pr constraints add constraint fi constraints map get fi q g p v constraints add pr constraints bit set instances constraints = bit set data size max ent p r constraint constraint constraints bit set bitset = constraint pre process data instances constraints or bitset instance list unlabeled = data clone empty ii = 0 ii < data size ii++ instances constraints get ii no label = data get ii get target == no label data get ii un lock data get ii set target label label alphabet data get target alphabet unlabeled add data get ii num features = unlabeled get data alphabet size setup model num = num features + 1 unlabeled get target alphabet size p == p = max ent unlabeled get pipe num setup aux model q = p r aux classifier unlabeled get pipe constraints old value = m a x v a l u e num iterations = 0 num iterations < max iterations num iterations++ base = optimize q unlabeled p num iterations==0 value = optimize p and compute value unlabeled q base p g p v logger info iteration + num iterations + total value + value num iterations >= min iterations 1 2 0 math abs value old value <= tolerance math abs value + math abs old value + 1e 5 logger info p r value difference below tolerance old value + old value + value + value + converged = old value = value p optimize p and compute value instance list data p r aux classifier q base p g p v instance list data labeled = data clone empty entropy = 0 num labels = data get target alphabet size ii = 0 ii < data size ii++ scores = num labels q get classification scores data get ii scores = 0 < num labels li++ base != base ii == 0 scores = n e g a t i v e i n f i n i t y base != log p = math log base ii scores += log p matrix ops exp normalize scores entropy += maths get entropy scores label vector lv = label vector label alphabet data get target alphabet scores instance instance = instance data get ii get data lv data labeled add instance train supervised max ent optimizable label opt = max ent optimizable label data labeled p opt set gaussian prior variance p g p v limited memory b f g s bfgs = limited memory b f g s opt bfgs optimize e e print stack trace bfgs reset bfgs optimize e e print stack trace value = 0 max ent p r constraint constraint q get constraint features plus sign because negative values value += constraint get complete value contribution value += entropy + opt get value value optimize q instance list data classifier p first iter num labels = data get target alphabet size base first iter base = base = data size num labels ii = 0 ii < data size ii++ p classify data get ii get label vector add to base ii p r aux classifier optimizable optimizable = p r aux classifier optimizable data base q limited memory b f g s bfgs = limited memory b f g s optimizable bfgs optimize e e print stack trace bfgs reset bfgs optimize e e print stack trace base 