topics value and gradient functions dirichlet multinomial regression guimaraes and lindrooth a general introduction to d m r and mimno and mc callum u a i 2008 an application to multinomial mixture models optimize optimizable classify max ent types instance list types instance types alphabet types feature vector types dirichlet types matrix ops logger progress message logger logging text number format text decimal format gnu trove t hash map d m r optimizable optimizable gradient value logger logger = logger get logger d m r optimizable get name logger progress logger = progress message logger get logger d m r optimizable get name + pl max ent classifier instance list training list num get value calls = 0 num get value gradient calls = 0 num iterations = m a x v a l u e number format formatter = d e f a u l t g a u s s i a n p r i o r v a r i a n e = 1 d e f a u l t l a r g e g a u s s i a n p r i o r v a r i a n e = 100 d e f a u l t g a u s s i a n p r i o r m e a n = 0 0 gaussian prior mean = d e f a u l t g a u s s i a n p r i o r m e a n gaussian prior variance = d e f a u l t g a u s s i a n p r i o r v a r i a n e allowing feature base level to fluctuate more freely than feature leads to much better results feature gaussian prior variance = d e f a u l t l a r g e g a u s s i a n p r i o r v a r i a n e cached gradient cached value cached value stale cached gradient stale num labels num features feature index d m r optimizable d m r optimizable instance list instances max ent initial classifier training list = instances alphabet alphabet = instances get data alphabet alphabet label alphabet = instances get target alphabet num labels = label alphabet size add one feature feature num features = alphabet size + 1 add a spot intercept term out num features + num features + num labels + num labels feature index = num features 1 = num labels num features constraints = num labels num features cached gradient = num labels num features initial classifier != classifier = initial classifier = classifier get feature index = classifier get feature index initial classifier get instance pipe == instances get pipe classifier == classifier = max ent instances get pipe formatter = decimal format 0 ### e0 cached value stale = cached gradient stale = initialize constraints logger fine number instances in training list = + training list size instance instance training list feature vector multinomial values = feature vector instance get target multinomial values == feature vector features = feature vector instance get data features get alphabet == alphabet has na n = i = 0 i < features num locations i++ na n features value at location i logger info na n feature + alphabet lookup features index at location i to has na n = has na n logger info na n in instance + instance get name test maximizable test value and gradient current set variance features aka intercept generally larger than variance regular features set intercept gaussian prior variance sigma squared feature gaussian prior variance = sigma squared set variance regular non features generally smaller than variance features set regular gaussian prior variance sigma squared gaussian prior variance = sigma squared max ent get classifier classifier get parameter index index set parameter index v cached value stale = cached gradient stale = index = v get num length get buff buff == || buff length != length buff = length arraycopy 0 buff 0 length set buff buff != cached value stale = cached gradient stale = buff length != length = buff length arraycopy buff 0 0 buff length log probability observed count vectors given features get value ! cached value stale cached value num get value calls++ cached value = 0 incorporate likelihood data scores = training list get target alphabet size value = 0 0 instance index = 0 instance instance training list feature vector multinomial values = feature vector instance get target multinomial values == out l now +input alphabet size + regular features get predicted probability each current model classifier get unnormalized classification scores instance scores sum scores = 0 0 exponentiate scores i=0 i<scores length i++ due to underflow it s very likely that some these scores will be 0 0 scores i = math exp scores i sum scores += scores i feature vector features = feature vector instance get data really an but since feature vectors are defined doubles avoid casting total length = 0 i = 0 i < multinomial values num locations i++ label = multinomial values index at location i count = multinomial values value at location i value += dirichlet log gamma stirling scores label + count dirichlet log gamma stirling scores label total length += count value = dirichlet log gamma stirling sum scores + total length dirichlet log gamma stirling sum scores checking na n value logger fine d m max ent trainer instance + instance get name + has na n value label multinomial values get indices logger fine log scores = + math log scores label + scores = + scores label infinite value logger warning instance + instance get source + has infinite value skipping value and gradient cached value = value cached value stale = value out value cached value += value instance index++ incorporate prior on prior = 0 log a gaussian prior x^2 2sigma^2 label = 0 label < num labels label++ feature = 0 feature < num features 1 feature++ = label num features + feature prior = gaussian prior mean gaussian prior mean 2 gaussian prior variance = label num features + feature index prior = gaussian prior mean gaussian prior mean 2 feature gaussian prior variance label probability = cached value cached value += prior cached value stale = progress logger info value likelihood= + formatter format label probability + prior= + formatter format prior + = + formatter format cached value cached value get value gradient buffer matrix ops set all cached gradient 0 0 incorporate likelihood data scores = training list get target alphabet size instance index = 0 instance instance training list feature vector multinomial values = feature vector instance get target multinomial values == get predicted probability each current model classifier get unnormalized classification scores instance scores sum scores = 0 0 exponentiate scores i=0 i<scores length i++ due to underflow it s very likely that some these scores will be 0 0 scores i = math exp scores i sum scores += scores i feature vector features = feature vector instance get data total length = 0 count multinomial values get values total length += count digamma difference sums = dirichlet digamma sum scores + total length dirichlet digamma sum scores loc = 0 loc < features num locations loc++ index = features index at location loc value = features value at location loc value == 0 0 in a feature vector there s no easy way to say you know about id? so i ve broken into two loops one all labels other just non zero ones label=0 label<num labels label++ cached gradient label num features + index = value scores label digamma difference sums label loc = 0 label loc <multinomial values num locations label loc++ label = multinomial values index at location label loc count = multinomial values value at location label loc diff = 0 0 count < 20 i=0 i < count i++ diff += 1 scores label + i diff = dirichlet digamma scores label + count dirichlet digamma scores label cached gradient label num features + index += value scores label diff now add feature label=0 label<num labels label++ cached gradient label num features + feature index = scores label digamma difference sums label loc = 0 label loc <multinomial values num locations label loc++ label = multinomial values index at location label loc count = multinomial values value at location label loc diff = 0 0 count < 20 i=0 i < count i++ diff += 1 scores label + i diff = dirichlet digamma scores label + count dirichlet digamma scores label cached gradient label num features + feature index += scores label diff num get value gradient calls++ label = 0 label < num labels label++ feature = 0 feature < num features 1 feature++ = label num features + feature cached gradient label num features + feature = gaussian prior mean gaussian prior variance = label num features + feature index cached gradient label num features + feature index = gaussian prior mean feature gaussian prior variance a parameter may be set to infinity an external user we set gradient to 0 because parameter s value can never change anyway and it will mess up future calculations on matrix such norm matrix ops substitute cached gradient n e g a t i v e i n f i n i t y 0 0 buffer != buffer length == length arraycopy cached gradient 0 buffer 0 cached gradient length out d m max ent trainer gradient infinity norm = + matrix ops infinity norm cached gradient 